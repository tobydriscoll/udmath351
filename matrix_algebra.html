<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.339">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Notes for Math 351 @ UD - 4&nbsp; Matrix algebra</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./eigen.html" rel="next">
<link href="./linear_algebra_systems.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script> 
MathJax = {
  chtml: {
    scale: 0.92,
  }
}
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./matrix_algebra.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Matrix algebra</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Notes for Math 351 @ UD</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Contents</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ivp_first_order.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">First-order IVPs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ivp_second_order.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Second-order linear IVPs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./linear_algebra_systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Linear algebraic systems</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./matrix_algebra.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Matrix algebra</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eigen.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Eigenvalues</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ode_systems.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Systems of ODEs</span></span></a>
  </div>
</li>
    </ul>
    </div>
<div class="quarto-sidebar-footer"><div class="sidebar-footer-item">
<p>Copyright 2023 by Toby Driscoll</p>
</div></div></nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#elementwise-operations" id="toc-elementwise-operations" class="nav-link active" data-scroll-target="#elementwise-operations"><span class="header-section-number">4.1</span> Elementwise operations</a></li>
  <li><a href="#matrix-times-vector" id="toc-matrix-times-vector" class="nav-link" data-scroll-target="#matrix-times-vector"><span class="header-section-number">4.2</span> Matrix times vector</a>
  <ul class="collapse">
  <li><a href="#properties" id="toc-properties" class="nav-link" data-scroll-target="#properties"><span class="header-section-number">4.2.1</span> Properties</a></li>
  <li><a href="#connection-to-linear-systems" id="toc-connection-to-linear-systems" class="nav-link" data-scroll-target="#connection-to-linear-systems"><span class="header-section-number">4.2.2</span> Connection to linear systems</a></li>
  </ul></li>
  <li><a href="#sec-matrix-times-matrix" id="toc-sec-matrix-times-matrix" class="nav-link" data-scroll-target="#sec-matrix-times-matrix"><span class="header-section-number">4.3</span> Matrix times matrix</a>
  <ul class="collapse">
  <li><a href="#counterintuitive-observations" id="toc-counterintuitive-observations" class="nav-link" data-scroll-target="#counterintuitive-observations"><span class="header-section-number">4.3.1</span> Counterintuitive observations</a></li>
  <li><a href="#properties-1" id="toc-properties-1" class="nav-link" data-scroll-target="#properties-1"><span class="header-section-number">4.3.2</span> Properties</a></li>
  <li><a href="#matrix-powers" id="toc-matrix-powers" class="nav-link" data-scroll-target="#matrix-powers"><span class="header-section-number">4.3.3</span> Matrix powers</a></li>
  </ul></li>
  <li><a href="#identity-and-inverse" id="toc-identity-and-inverse" class="nav-link" data-scroll-target="#identity-and-inverse"><span class="header-section-number">4.4</span> Identity and inverse</a>
  <ul class="collapse">
  <li><a href="#identity-matrix" id="toc-identity-matrix" class="nav-link" data-scroll-target="#identity-matrix"><span class="header-section-number">4.4.1</span> Identity matrix</a></li>
  <li><a href="#inverse" id="toc-inverse" class="nav-link" data-scroll-target="#inverse"><span class="header-section-number">4.4.2</span> Inverse</a></li>
  <li><a href="#properties-2" id="toc-properties-2" class="nav-link" data-scroll-target="#properties-2"><span class="header-section-number">4.4.3</span> Properties</a></li>
  <li><a href="#diagonal-matrix" id="toc-diagonal-matrix" class="nav-link" data-scroll-target="#diagonal-matrix"><span class="header-section-number">4.4.4</span> Diagonal matrix</a></li>
  <li><a href="#times-2" id="toc-times-2" class="nav-link" data-scroll-target="#times-2"><span class="header-section-number">4.4.5</span> <span class="math inline">\(2\times 2\)</span></a></li>
  </ul></li>
  <li><a href="#fundamental-theorem" id="toc-fundamental-theorem" class="nav-link" data-scroll-target="#fundamental-theorem"><span class="header-section-number">4.5</span> Fundamental Theorem</a></li>
  <li><a href="#sec-matrix-subspaces" id="toc-sec-matrix-subspaces" class="nav-link" data-scroll-target="#sec-matrix-subspaces"><span class="header-section-number">4.6</span> Subspaces</a>
  <ul class="collapse">
  <li><a href="#column-space" id="toc-column-space" class="nav-link" data-scroll-target="#column-space"><span class="header-section-number">4.6.1</span> Column space</a></li>
  <li><a href="#null-space" id="toc-null-space" class="nav-link" data-scroll-target="#null-space"><span class="header-section-number">4.6.2</span> Null space</a></li>
  <li><a href="#basis" id="toc-basis" class="nav-link" data-scroll-target="#basis"><span class="header-section-number">4.6.3</span> Basis</a></li>
  <li><a href="#dimension" id="toc-dimension" class="nav-link" data-scroll-target="#dimension"><span class="header-section-number">4.6.4</span> Dimension</a></li>
  </ul></li>
  <li><a href="#other-vector-spaces" id="toc-other-vector-spaces" class="nav-link" data-scroll-target="#other-vector-spaces"><span class="header-section-number">4.7</span> Other vector spaces</a>
  <ul class="collapse">
  <li><a href="#matrices" id="toc-matrices" class="nav-link" data-scroll-target="#matrices"><span class="header-section-number">4.7.1</span> Matrices</a></li>
  <li><a href="#polynomials" id="toc-polynomials" class="nav-link" data-scroll-target="#polynomials"><span class="header-section-number">4.7.2</span> Polynomials</a></li>
  <li><a href="#ode-solutions" id="toc-ode-solutions" class="nav-link" data-scroll-target="#ode-solutions"><span class="header-section-number">4.7.3</span> ODE solutions</a></li>
  </ul></li>
  <li><a href="#coordinates" id="toc-coordinates" class="nav-link" data-scroll-target="#coordinates"><span class="header-section-number">4.8</span> Coordinates</a>
  <ul class="collapse">
  <li><a href="#computing-coordinates" id="toc-computing-coordinates" class="nav-link" data-scroll-target="#computing-coordinates"><span class="header-section-number">4.8.1</span> Computing coordinates</a></li>
  </ul></li>
  <li><a href="#change-of-basis" id="toc-change-of-basis" class="nav-link" data-scroll-target="#change-of-basis"><span class="header-section-number">4.9</span> Change of basis</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Matrix algebra</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>

<div class="hidden">
<p><span class="math display">\[
    \newcommand{\float}{\mathbb{F}}
    \newcommand{\real}{\mathbb{R}}
    \newcommand{\complex}{\mathbb{C}}
    \newcommand{\nat}{\mathbb{N}}
    \newcommand{\integer}{\mathbb{Z}}
    \newcommand{\bfa}{\mathbf{a}}
    \newcommand{\bfb}{\mathbf{b}}
    \newcommand{\bfc}{\mathbf{c}}
    \newcommand{\bfe}{\mathbf{e}}
    \newcommand{\bff}{\mathbf{f}}
    \newcommand{\bfh}{\mathbf{h}}
    \newcommand{\bfp}{\mathbf{p}}
    \newcommand{\bfq}{\mathbf{q}}
    \newcommand{\bfu}{\mathbf{u}}
    \newcommand{\bfv}{\mathbf{v}}
    \newcommand{\bfw}{\mathbf{w}}
    \newcommand{\bfx}{\mathbf{x}}
    \newcommand{\bfy}{\mathbf{y}}
    \newcommand{\bfz}{\mathbf{z}}
    \newcommand{\bfA}{\mathbf{A}}
    \newcommand{\bfB}{\mathbf{B}}
    \newcommand{\bfD}{\mathbf{D}}
    \newcommand{\bfE}{\mathbf{E}}
    \newcommand{\bfP}{\mathbf{P}}
    \newcommand{\bfV}{\mathbf{V}}
    \newcommand{\bfW}{\mathbf{W}}
    \newcommand{\bfX}{\mathbf{X}}
    \newcommand{\fundm}{\boldsymbol{\Phi}}
    \newcommand{\bfzero}{\boldsymbol{0}}
    \newcommand{\bfmu}{\boldsymbol{\mu}}
    \newcommand{\opA}{\mathcal{A}}
    \newcommand{\rmn}[2]{\mathbb{R}^{#1 \times #2}}
    \newcommand{\cmn}[2]{\mathbb{C}^{#1 \times #2}}
    \newcommand{\dd}[2]{\frac{d #1}{d #2}}
    \newcommand{\ddd}[2]{\frac{d^2 #1}{d #2^2}}
    \newcommand{\pp}[2]{\frac{\partial #1}{\partial #2}}
    \newcommand{\norm}[1]{\left\lVert \mathstrut #1 \right\rVert}
    \newcommand{\abs}[1]{\left\lvert \mathstrut #1 \right\rvert}
    \newcommand{\twonorm}[1]{\norm{#1}_2}
    \newcommand{\onenorm}[1]{\norm{#1}_1}
    \newcommand{\infnorm}[1]{\norm{#1}_\infty}
    \newcommand{\innerprod}[2]{\langle #1,#2 \rangle}
    \newcommand{\pr}[1]{^{(#1)}}
    \newcommand{\diagm}[3]{\begin{bmatrix} #1 &amp; &amp; &amp; \\ &amp; #2 &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; #3 \end{bmatrix}}
    \newcommand{\twovec}[2]{\begin{bmatrix} #1 \\ #2 \end{bmatrix}}
    \newcommand{\threevec}[3]{\begin{bmatrix} #1 \\ #2 \\ #3 \end{bmatrix}}
    \newcommand{\twomat}[4]{\begin{bmatrix} #1 &amp; #2 \\ #3 &amp; #4 \end{bmatrix}}
    \newcommand{\twodet}[4]{\begin{vmatrix} #1 &amp; #2 \\ #3 &amp; #4 \end{vmatrix}}
    \newcommand{\eye}[1]{\mathbf{e}_#1}
    \newcommand{\meye}{\mathbf{I}}
    \newcommand{\diag}{\operatorname{diag}}
    \newcommand{\sign}{\operatorname{sign}}
    \newcommand{\dist}{\operatorname{dist}}
    \newcommand{\simil}{\operatorname{sim}}
    \newcommand{\vec}{\operatorname{vec}}
    \newcommand{\unvec}{\operatorname{unvec}}
    \newcommand{\ee}{\times 10^}
    \newcommand{\floor}[1]{\lfloor#1\rfloor}
    \newcommand{\argmin}{\operatorname{argmin}}
    \newcommand{\rank}{\operatorname{rank}}
    \newcommand{\span}{\operatorname{span}}
    \newcommand{\nullsp}{\operatorname{nullsp}}
    \newcommand{\nullity}{\operatorname{nullity}}
    \newcommand{\rowsp}{\operatorname{rowsp}}
    \newcommand{\colsp}{\operatorname{colsp}}
    % \newcommand{\dimen}{\operatorname{dim}}
    \newcommand{\augmat}[2]{\left[ #1 \;\middle|\; #2 \right]}
\]</span></p>
</div>
<p>We now dive deeply into the world of vectors and matrices. There are a ton of new facts in this chapter, presented in the mathematical form of definitions and theorems so that they are stated precisely. But the terminology overlaps tremendously, and there are actually relatively few unique ideas.</p>
<section id="elementwise-operations" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="elementwise-operations"><span class="header-section-number">4.1</span> Elementwise operations</h2>
<p>In this game, we often refer to mere numbers as <strong>scalars</strong>. That’s because they just scale every element, like in</p>
<p><span class="math display">\[
c \begin{bmatrix}
A_{11} &amp; \cdots &amp; A_{1n} \\
\vdots &amp; &amp; \vdots \\
A_{m1} &amp; \cdots &amp; A_{mn}
\end{bmatrix}
=
\begin{bmatrix}
cA_{11} &amp; \cdots &amp; cA_{1n} \\
\vdots &amp; &amp; \vdots \\
cA_{m1} &amp; \cdots &amp; cA_{mn}
\end{bmatrix}.
\]</span></p>
<p>It’s easy to add or subtract two vectors or two matrices that have the same size. Just act elementwise:</p>
<p><span class="math display">\[
\begin{bmatrix}
A_{11} &amp; \cdots &amp; A_{1n} \\
\vdots &amp; &amp; \vdots \\
A_{m1} &amp; \cdots &amp; A_{mn}
\end{bmatrix}
+
\begin{bmatrix}
B_{11} &amp; \cdots &amp; B_{1n} \\
\vdots &amp; &amp; \vdots \\
B_{m1} &amp; \cdots &amp; B_{mn}
\end{bmatrix}
=
\begin{bmatrix}
A_{11}+B_{11} &amp; \cdots &amp; A_{1n}+B_{1n} \\
\vdots &amp; &amp; \vdots \\
A_{m1}+B_{m1} &amp; \cdots &amp; A_{mn}+B_{mn}
\end{bmatrix}
\]</span></p>
<p>We consider the operation of adding matrices of <em>different</em> sizes to be undefined.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Mathematically, we leave the operation of adding a scalar to a vector or matrix undefined as well, although MATLAB and NumPy will happily do that for you.</p>
</div>
</div>
<p>You would probably expect that we define matrix multiplication similarly:</p>
<p><span class="math display">\[
\begin{bmatrix}
A_{11} &amp; \cdots &amp; A_{1n} \\
\vdots &amp; &amp; \vdots \\
A_{m1} &amp; \cdots &amp; A_{mn}
\end{bmatrix}
\cdot
\begin{bmatrix}
B_{11} &amp; \cdots &amp; B_{1n} \\
\vdots &amp; &amp; \vdots \\
B_{m1} &amp; \cdots &amp; B_{mn}
\end{bmatrix}
\stackrel{??}{=}
\begin{bmatrix}
A_{11}B_{11} &amp; \cdots &amp; A_{1n}B_{1n} \\
\vdots &amp; &amp; \vdots \\
A_{m1}B_{m1} &amp; \cdots &amp; A_{mn}B_{mn}
\end{bmatrix}
\]</span></p>
<p>But we don’t! OK, <em>technically</em> this is called a Hadamard product, and it has some uses. But 99.9999% of the time a different, less obvious way of multiplying matrices does a better job of respecting critical mathematical structure.</p>
</section>
<section id="matrix-times-vector" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="matrix-times-vector"><span class="header-section-number">4.2</span> Matrix times vector</h2>
<p>The idea of linear combinations, as defined in <a href="linear_algebra_systems.html#def-linalg-linear-comb" class="quarto-xref">Definition&nbsp;<span>3.11</span></a>, serves as the foundation of multiplication between a matrix and a vector.</p>
<div id="def-operations-matvec" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.1 (Matrix times vector) </strong></span>Given <span class="math inline">\(\bfA\in\cmn{m}{n}\)</span> and <span class="math inline">\(\bfx\in\complex^{n}\)</span>, the product <span class="math inline">\(\bfA\bfx\)</span> is defined as</p>
<p><span id="eq-operations-matvec"><span class="math display">\[
\bfA\bfx = x_1 \bfa_1 + x_2 \bfa_2 + \cdots + x_n \bfa_n = \sum_{j=1}^n x_j \bfa_j,
\tag{4.1}\]</span></span></p>
<p>where <span class="math inline">\(\bfa_j\)</span> refers to the <span class="math inline">\(j\)</span>th column of <span class="math inline">\(\bfA\)</span>.</p>
</div>
<div class="callout-attention">
<p>In order for <span class="math inline">\(\bfA\bfx\)</span> to be defined, the number of columns in <span class="math inline">\(\bfA\)</span> has to be the same as the number of elements in <span class="math inline">\(\bfx\)</span>.</p>
</div>
<p>Note that when <span class="math inline">\(\bfA\)</span> is <span class="math inline">\(m\times n\)</span>, then <span class="math inline">\(\bfx\)</span> must be in <span class="math inline">\(\real^n\)</span> or <span class="math inline">\(\complex^n\)</span>, and <span class="math inline">\(\bfA\bfx\)</span> has dimension <span class="math inline">\(m\)</span>.</p>
<div id="exm-matvec" class="theorem example" data-chapter="4" data-description="Matrix--vector product">
<p><span class="theorem-title"><strong>Example 4.1 </strong></span>Calculate the product</p>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; -1 &amp; -1 \\ 3 &amp; -2 &amp; 0 \\ 1 &amp; -2 &amp; -1 \end{bmatrix} \threevec{-1}{2}{-1}.
\]</span></p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>The product is equivalent to</p>
<p><span class="math display">\[
(-1) \threevec{1}{3}{1} + (2) \threevec{-1}{-2}{-2} + (-1) \threevec{-1}{0}{-1} = \threevec{-2}{-7}{-4}.
\]</span></p>
<p>We don’t often write out the product in this much detail. Instead we “zip together” the rows of the matrix with the entries of the vector:</p>
<p><span class="math display">\[
\threevec{(-1)(1)+(2)(-1)+(-1)(-1)}{(-1)(3)+(2)(-2)+(-1)(0)}{(-1)(1)+(2)(-2)+(-1)(-1)}  = \threevec{-2}{-7}{-4}.
\]</span></p>
<p>You might recognize the “zip” expressions in this vector as dot products from vector calculus.</p>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>We can regard a vector <span class="math inline">\(\bfx \in \real^n\)</span> as also being a matrix, in two ways: as a member of <span class="math inline">\(\rmn{1}{n}\)</span>, making it a <strong>row vector</strong>, or as a member of <span class="math inline">\(\rmn{n}{1}\)</span>, making it a <strong>column vector</strong>. Our convention is that <em>when we want to interpret a named vector as a matrix, it’s a column vector.</em></p>
<p>However, that Python assumes a row vector, MATLAB lets you choose either, and Julia considers it a column vector. It’s a mess that can lead to frustrating errors in computer codes.</p>
</div>
</div>
<section id="properties" class="level3" data-number="4.2.1">
<h3 data-number="4.2.1" class="anchored" data-anchor-id="properties"><span class="header-section-number">4.2.1</span> Properties</h3>
<p>What justifies calling this operation multiplication? In large part, it’s the natural distributive properties</p>
<p><span class="math display">\[
\begin{split}
\bfA(\bfx+\bfy) &amp; =  \bfA\bfx + \bfA\bfy,\\
(\bfA+\bfB)\bfx &amp; =  \bfA\bfx + \bfB\bfx,
\end{split},
\]</span></p>
<p>along with</p>
<p><span class="math display">\[
\bfA(c\bfx)=c(\bfA\bfx)
\]</span></p>
<p>for any scalar <span class="math inline">\(c\)</span>.</p>
<p>But there is a <em>major</em> departure from multiplication as we usually know it.</p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Matrix-vector products are not commutative. In fact, <span class="math inline">\(\bfx\bfA\)</span> is not defined even when <span class="math inline">\(\bfA\bfx\)</span> is.</p>
</div>
</div>
<p>This is the first time we see something that will happen more generally:</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The order of the terms in a product of non-scalars cannot be changed without some explicit justification.</p>
</div>
</div>
</section>
<section id="connection-to-linear-systems" class="level3" data-number="4.2.2">
<h3 data-number="4.2.2" class="anchored" data-anchor-id="connection-to-linear-systems"><span class="header-section-number">4.2.2</span> Connection to linear systems</h3>
<p>The following observation finally brings us back around to the introduction of linear systems through the insultingly simple scalar equation <span class="math inline">\(ax=b\)</span>.</p>
<div id="thm-Ax-eq-b" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.1 </strong></span>The linear system with coefficient matrix <span class="math inline">\(\bfA\)</span>, forcing vector <span class="math inline">\(\bfb\)</span>, and solution <span class="math inline">\(\bfx\)</span> is equivalent to the equation <span class="math inline">\(\bfA\bfx=\bfb\)</span>.</p>
</div>
<p>The following result follows quickly from our definitions.</p>
<div id="thm-b-in-span" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.2 </strong></span>The linear system <span class="math inline">\(\bfA\bfx=\bfb\)</span> is consistent if and only if <span class="math inline">\(\bfb\)</span> is in the span of the columns of <span class="math inline">\(\bfA\)</span>.</p>
</div>
<!-- ### Connection to independence

Because $\bfA\bfx$ is a linear combination of $\bfA$'s columns, statements we made previously in connection with linear combinations have corresponding restatements in terms of matrix columns.

::::{#thm-dependent-columns}
The null space of a matrix contains nonzero vectors if and only if the columns of the matrix are linearly dependent.
::::

:::{.proof}
Vector $\bfx$ is in the nullspace of $\bfA$ if and only if $\bfA\bfx=\bfzero$. Therefore, if $\bfx$ is nonzero, then we have a nontrivial linear combination of $\bfA$'s columns that gives the zero vector.
::: -->
</section>
</section>
<section id="sec-matrix-times-matrix" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="sec-matrix-times-matrix"><span class="header-section-number">4.3</span> Matrix times matrix</h2>
<p>We can think of vectors as a special kind of matrix, and accordingly we can generalize matrix-vector products to matrix-matrix products. There are many equivalent ways to define these products. Here is the one we start with.</p>
<div id="def-operations-matmat" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.2 (Matrix times matrix) </strong></span>If <span class="math inline">\(\bfA\)</span> is <span class="math inline">\(m\times n\)</span> and <span class="math inline">\(\bfB\)</span> is <span class="math inline">\(n\times p\)</span>, then the product <span class="math inline">\(\bfA\bfB\)</span> is defined as</p>
<p><span id="eq-matrix-mult"><span class="math display">\[
\bfA\mathbf{B}
= \bfA \begin{bmatrix} \mathbf{b}_1 &amp; \mathbf{b}_2 &amp; \cdots &amp; \mathbf{b}_p \end{bmatrix}
= \begin{bmatrix} \bfA\mathbf{b}_1 &amp; \bfA\mathbf{b}_2 &amp; \cdots &amp; \bfA\mathbf{b}_p \end{bmatrix}.
\tag{4.2}\]</span></span></p>
</div>
<p>In words, a matrix-matrix product is the horizontal concatenation of matrix-vector products involving the columns of the right-hand matrix.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>In order to define <span class="math inline">\(\bfA\bfB\)</span>, we require that the number of columns in <span class="math inline">\(\bfA\)</span> is the same as the number of rows in <span class="math inline">\(\bfB\)</span>. That is, the <em>inner dimensions</em> must agree. The result has size determined by the <em>outer dimensions</em> of the original matrices.</p>
</div>
</div>
<p>When we compute a matrix product by hand, we usually don’t write out the above. Instead we use a more compact definition for the individual entries of <span class="math inline">\(\mathbf{C} = \bfA\bfB\)</span>,</p>
<p><span id="eq-matrix-mult-element"><span class="math display">\[
C_{ij} = \sum_{k=1}^n a_{ik}b_{kj}, \qquad i=1,\ldots,m, \quad j=1,\ldots,p.
\tag{4.3}\]</span></span></p>
<p>In words:</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The <span class="math inline">\((i,j)\)</span> entry of the matrix product <span class="math inline">\(\bfA \bfB\)</span> is the dot product of row <span class="math inline">\(i\)</span> of <span class="math inline">\(\bfA\)</span> with column <span class="math inline">\(j\)</span> of <span class="math inline">\(\bfB\)</span>.</p>
</div>
</div>
<div id="exm-matmat" class="theorem example" data-chapter="4" data-description="Matrix--matrix product">
<p><span class="theorem-title"><strong>Example 4.2 </strong></span>Find <span class="math inline">\(\mathbf{A}\mathbf{B}\)</span> if</p>
<p><span class="math display">\[
\bfA = \begin{bmatrix}
1 &amp; -1 \\ 0 &amp; 2 \\ -3 &amp; 1
\end{bmatrix}, \qquad
\mathbf{B} = \begin{bmatrix}
2 &amp; -1 &amp; 0 &amp; 4 \\ 1 &amp; 1 &amp; 3 &amp; 2
\end{bmatrix}.
\]</span></p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>Using <a href="#eq-matrix-mult-element" class="quarto-xref">Equation&nbsp;<span>4.3</span></a>,</p>
<p><span class="math display">\[
\begin{split}
\bfA\mathbf{B} &amp;= \begin{bmatrix}
(1)(2) + (-1)(1) &amp; (1)(-1) + (-1)(1) &amp; (1)(0) + (-1)(3) &amp; (1)(4) + (-1)(2) \\
(0)(2) + (2)(1) &amp; (0)(-1) + (2)(1) &amp; (0)(0) + (2)(3) &amp; (0)(4) + (2)(2) \\
(-3)(2) + (1)(1) &amp; (-3)(-1) + (1)(1) &amp; (-3)(0) + (1)(3) &amp; (-3)(4) + (1)(2)
\end{bmatrix} \\
&amp; = \begin{bmatrix}
1 &amp; -2 &amp; -3 &amp; 2 \\ 2 &amp; 2 &amp; 6 &amp; 4 \\ -5 &amp; 4 &amp; 3 &amp; -10
\end{bmatrix}
\end{split}.
\]</span></p>
<p>Observe that</p>
<p><span class="math display">\[
\bfA \begin{bmatrix} 2 \\ 1 \end{bmatrix} = 2 \begin{bmatrix} 1 \\ 0 \\ -3
\end{bmatrix} + 1 \begin{bmatrix} -1 \\ 2 \\ 1 \end{bmatrix}
= \begin{bmatrix} 1 \\ 2 \\ -5 \end{bmatrix},
\]</span></p>
<p>and so on.</p>
</div>
</div>
<section id="counterintuitive-observations" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="counterintuitive-observations"><span class="header-section-number">4.3.1</span> Counterintuitive observations</h3>
<p>Even though matrix multiplication has a lot of similarity to scalar multiplication, there are some fundamental differences.</p>
<div id="exm-matmult-noBA" class="theorem example" data-chapter="4" data-description="**AB** but not **BA**">
<p><span class="theorem-title"><strong>Example 4.3 </strong></span>Suppose</p>
<p><span class="math display">\[
\bfA = \begin{bmatrix} 1 &amp; 2 &amp; -2 \\ 3 &amp; 0 &amp; 0 \end{bmatrix}, \qquad \bfB = \begin{bmatrix} 0 &amp; -1 &amp; -1 \\ 1 &amp; 1 &amp; 0 \\ 1 &amp; 2 &amp; 3\end{bmatrix}.
\]</span></p>
<p>Then</p>
<p><span class="math display">\[
\bfA \bfB = \begin{bmatrix} 0 + 2 - 2 &amp; -1 + 2 - 4 &amp; -1 + 0 - 6 \\ 0 + 0 + 0 &amp; -3 + 0 + 0 &amp; -3+0+0 \end{bmatrix} = \begin{bmatrix} 0 &amp; -3 &amp; -7 \\ 0 &amp; -3 &amp; -3 \end{bmatrix}.
\]</span></p>
<p>But <span class="math inline">\(\bfB\bfA\)</span> is not defined, because <span class="math inline">\(\bfB\)</span> is <span class="math inline">\(3\times 3\)</span> and <span class="math inline">\(\bfA\)</span> is <span class="math inline">\(2\times 3\)</span>.</p>
</div>
<div id="exm-matmult-noncommutative" class="theorem example" data-chapter="4" data-description="Matrix multiplication is not commutative">
<p><span class="theorem-title"><strong>Example 4.4 </strong></span>Suppose</p>
<p><span class="math display">\[
\bfA = \begin{bmatrix}  2 &amp; -2 \\ 1 &amp; 1 \end{bmatrix}, \qquad \bfB = \begin{bmatrix} 0 &amp; -2 \\ 2 &amp; -1 \end{bmatrix}.
\]</span></p>
<p>Then</p>
<p><span class="math display">\[
\bfA\bfB = \begin{bmatrix} 0-4 &amp; -4+2 \\ 0+2 &amp; -2-1 \end{bmatrix} = \begin{bmatrix} -4 &amp; 2 \\ 1 &amp; -3 \end{bmatrix},
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\bfB\bfA = \begin{bmatrix} 0-2 &amp; 0 -2 \\ 4-1  &amp; -4-1\end{bmatrix} = \begin{bmatrix} -2 &amp; -2 \\ 3 &amp; -5 \end{bmatrix}.
\]</span></p>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>Matrix multiplication is not commutative. If <span class="math inline">\(\bfA\bfB\)</span> is defined, then <span class="math inline">\(\bfB\bfA\)</span> may not be, and even if it is, it may not equal <span class="math inline">\(\bfA\bfB\)</span>.</p>
<p>In other words, you cannot change the order of the terms in a matrix product without some explicit justification.</p>
</div>
</div>
<p>A <strong>zero matrix</strong> is a matrix of all zeros. When the sizes are compatible, the product of any matrix with a zero matrix is another zero matrix. But here is another critical difference from the scalar case.</p>
<div id="exm-matrix-cancellation" class="theorem example" data-chapter="4" data-description="Singular matrices">
<p><span class="theorem-title"><strong>Example 4.5 </strong></span>Let <span class="math inline">\(\bfA = \twomat{0}{0}{1}{0}\)</span>. Note that</p>
<p><span class="math display">\[
\bfA \bfA = \twomat{0}{0}{1}{0} \cdot \twomat{0}{0}{1}{0} = \twomat{0}{0}{0}{0}.
\]</span></p>
</div>
<p>As a result, we <strong>cannot</strong> make the implication <span class="math display">\[
\bfA\bfB = \bfzero \implies \bfA = \bfzero \text{ or } \bfB=\bfzero \qquad \text{(FALSE!)}
\]</span></p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>It is possible for the product of two nonzero matrices to be zero.</p>
</div>
</div>
<p>If you think about it, <a href="#exm-matrix-cancellation" class="quarto-xref">Example&nbsp;<span>4.5</span></a> also means that we lose another routine property of scalar multiplication:</p>
<p><span class="math display">\[
\bfA \bfB = \bfA \mathbf{C} \implies \bfB = \mathbf{C} \qquad \text{(FALSE!)}
\]</span></p>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Warning
</div>
</div>
<div class="callout-body-container callout-body">
<p>We cannot always cancel out a matrix appearing in a product on both sides of an equation.</p>
</div>
</div>
</section>
<section id="properties-1" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="properties-1"><span class="header-section-number">4.3.2</span> Properties</h3>
<p>Fortunately, other familiar and handy properties of scalar multiplication do come along for the ride:</p>
<ol type="1">
<li><span class="math inline">\((\bfA\bfB)\mathbf{C}=\bfA(\bfB \mathbf{C})\qquad\)</span> (association)</li>
<li><span class="math inline">\(\bfA(\bfB+\mathbf{C}) = \bfA\bfB + \bfA\mathbf{C}\qquad\)</span> (right distribution)</li>
<li><span class="math inline">\((\bfA+\bfB)\mathbf{C} = \bfA\mathbf{C} + \bfB\mathbf{C}\qquad\)</span> (left distribution)</li>
</ol>
<p>These properties are easy to check computationally. (But keep in mind that a numerical demonstration, or an algebraic one at particular sizes, is not a general proof.) In addition, matrix multiplication plays well with numbers:</p>
<ol type="1">
<li><span class="math inline">\((c\bfA \bfB) = c (\bfA \bfB) = \bfA (c \bfB)\)</span></li>
<li><span class="math inline">\(c(\bfA + \bfB) = (c\bfA) + (c\bfB)\)</span></li>
<li><span class="math inline">\((c+d) \bfA = (c\bfA) + (d\bfA)\)</span></li>
</ol>
<p>Finally, we observe that if <span class="math inline">\(\bfA\)</span> is <span class="math inline">\(m\times n\)</span> and <span class="math inline">\(\bfx\)</span> is an <span class="math inline">\(n\)</span>-vector, then <span class="math inline">\(\bfA\bfx\)</span> gives the same result whether we interpret <span class="math inline">\(\bfx\)</span> as a vector or as an <span class="math inline">\(n\times 1\)</span> matrix.</p>
</section>
<section id="matrix-powers" class="level3" data-number="4.3.3">
<h3 data-number="4.3.3" class="anchored" data-anchor-id="matrix-powers"><span class="header-section-number">4.3.3</span> Matrix powers</h3>
<p>When <span class="math inline">\(\bfA\)</span> is square, meaning <span class="math inline">\(n \times n\)</span>, we can define positive integer powers of <span class="math inline">\(\bfA\)</span> in the usual way:</p>
<p><span class="math display">\[
\bfA^2 = \bfA\cdot \bfA, \quad \bfA^3 = \bfA\cdot \bfA\cdot \bfA = \bfA^2\cdot \bfA = \bfA\cdot \bfA^2,
\]</span></p>
<p>and so on. We have to wait for the next section to define <span class="math inline">\(\bfA^0\)</span> and negative powers. (The question of noninteger powers of a matrix is a topic for a graduate-level math course.)</p>
<!-- ## Transpose

Here's a curious operation that we won't be using much, but it is important enough to know about.

::::{#def-algebra-transpose} 
# Matrix transpose
The **transpose** of $m\times n$ matrix $\bfA$, whose elements are $A_{ij}$, is the $n\times m$ matrix $\bfA^T$ with elements $A_{ji}$.
::::

When taking the transpose, rows become columns, and vice versa.

### Properties

(theorem-algebra-transpose)=
::::{#thm-} 
If $\bfA$ and $\bfB$ are matrices of compatible sizes, and $c$ is a number, then
1. $(\bfA^T)^T = \bfA$
2. $(\bfA+\bfB)^T = \bfA^T + \bfB^T$
3. $(c\bfA^T) = c(\bfA^T)$
4. $(\bfA\bfB)^T = \bfB^T \bfA^T$
::::

Only the last of these is not intuitively clear. -->
</section>
</section>
<section id="identity-and-inverse" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="identity-and-inverse"><span class="header-section-number">4.4</span> Identity and inverse</h2>
<p>You solve <span class="math inline">\(ax=b\)</span> for nonzero <span class="math inline">\(a\)</span> without thinking about it: <span class="math inline">\(x=b/a\)</span>. If we do break it down a little, we can see that when we multiply both sides of <span class="math inline">\(ax=b\)</span> by the number <span class="math inline">\(1/a\)</span>, then on the left the terms <span class="math inline">\(1/a\)</span> and <span class="math inline">\(a\)</span> combine to give <span class="math inline">\(1\)</span>, and <span class="math inline">\(1x=x\)</span>. So the key to the solution is the presence of a <em>multiplicative identity</em> value <span class="math inline">\(1\)</span>, and the existence of the <em>multiplicative inverse</em> <span class="math inline">\(1/a\)</span> when <span class="math inline">\(a\neq 0\)</span>. These two items are also a way to discuss the vector case <span class="math inline">\(\bfA\bfx=\bfb\)</span>.</p>
<section id="identity-matrix" class="level3" data-number="4.4.1">
<h3 data-number="4.4.1" class="anchored" data-anchor-id="identity-matrix"><span class="header-section-number">4.4.1</span> Identity matrix</h3>
<p>Suppose we are given an <span class="math inline">\(m\times n\)</span> matrix <span class="math inline">\(\bfA\)</span>. Writing its columns as the vectors <span class="math inline">\(\bfa_1,\ldots,\bfa_n\)</span>, we can make the rather obvious observations</p>
<p><span class="math display">\[
\begin{split}
\bfa_1 &amp;= 1\cdot \bfa_1 + 0 \cdot \bfa_2 + \cdots + 0\cdot \bfa_n,\\
\bfa_2 &amp;= 0\cdot \bfa_1 + 1 \cdot \bfa_2 + \cdots + 0\cdot \bfa_n,\\
&amp;\; \vdots \\
\bfa_n &amp;= 0\cdot \bfa_1 + 0 \cdot \bfa_2 + \cdots + 1\cdot \bfa_n.
\end{split}
\]</span></p>
<p>The purpose in using these expressions is to interpret them as linear combinations, and thus as matrix-vector products. Let’s define <span class="math inline">\(\bfe_j\)</span> for <span class="math inline">\(j=1,\ldots,n\)</span> as follows.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.3 (Standard vectors) </strong></span><span class="math display">\[
\text{$i$th component of }\bfe_j = \begin{cases} 1, &amp; i=j, \\ 0, &amp; i\neq j. \end{cases}
\]</span></p>
</div>
<p>Now we can write</p>
<p><span id="eq-identity-columns"><span class="math display">\[
\bfa_j = \bfA \bfe_j, \quad j=1,\ldots,n.
\tag{4.4}\]</span></span></p>
<p>Furthermore, we can use the definition of matrix products as a concatenation of matrix-vector products to derive</p>
<p><span class="math display">\[
\begin{split}
    \bfA &amp;= \begin{bmatrix} \bfa_1 &amp; \bfa_2 &amp; \cdots &amp; \bfa_n \end{bmatrix} \\
    &amp;=  \begin{bmatrix} \bfA\bfe_1 &amp; \bfA\bfe_2 &amp; \cdots &amp; \bfA\bfe_n \end{bmatrix}\\
    &amp;=  \bfA \begin{bmatrix} \bfe_1 &amp; \bfe_2 &amp; \cdots &amp; \bfe_n \end{bmatrix}.
\end{split}
\]</span></p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.4 (Identity matrix) </strong></span>The <span class="math inline">\(n\times n\)</span> <strong>identity matrix</strong> is</p>
<p><span class="math display">\[
\meye = \begin{bmatrix} \bfe_1 &amp; \bfe_2 &amp; \cdots &amp; \bfe_n \end{bmatrix} =
    \begin{bmatrix}
    1 &amp; 0 &amp; \cdots &amp; 0 &amp; 0 \\
    0 &amp; 1 &amp; \cdots &amp; 0 &amp; 0 \\
    &amp; &amp; \ddots &amp; &amp; \\
    0 &amp; 0 &amp; \cdots &amp; 1 &amp; 0 \\
    0 &amp; 0 &amp; \cdots &amp; 0 &amp; 1
    \end{bmatrix}.
\]</span></p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Sometimes, when we need to indicate the size of the identity, we use a subscript, as in <span class="math inline">\(\meye_4\)</span> to represent the <span class="math inline">\(4\times 4\)</span> case. Usually, though, it’s implied by the context.</p>
</div>
</div>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.3 (Multiplicative identity) </strong></span>If <span class="math inline">\(\bfA\)</span> is <span class="math inline">\(m\times n\)</span>, then <span class="math inline">\(\bfA = \meye_m \bfA = \bfA \meye_n\)</span>.</p>
</div>
<div id="exm-matrix-identity" class="theorem example" data-chapter="4" data-description="Identity matrix">
<p><span class="theorem-title"><strong>Example 4.6 </strong></span>Compute</p>
<p><span class="math display">\[
\begin{bmatrix}
7 &amp; -2 &amp; 11 \\ 1131 &amp; \pi &amp; -\sqrt{13}
\end{bmatrix}
\begin{bmatrix}
2 &amp; 0 &amp; 0 \\ 0 &amp; 2 &amp; 0 \\ 0 &amp; 0 &amp; 2
\end{bmatrix}.
\]</span></p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>You can grind through the multiplication algorithm, of course, but there is a shortcut:</p>
<p><span class="math display">\[
\begin{split}
    \begin{bmatrix} 7 &amp; -2 &amp; 11 \\ 1131 &amp; \pi &amp; -\sqrt{13} \end{bmatrix}
    \begin{bmatrix} 2 &amp; 0 &amp; 0 \\ 0 &amp; 2 &amp; 0 \\ 0 &amp; 0 &amp; 2 \end{bmatrix}
    &amp; = \begin{bmatrix} 7 &amp; -2 &amp; 11 \\ 1131 &amp; \pi &amp; -\sqrt{13} \end{bmatrix}
    \left( 2 \begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{bmatrix} \right) \\
    &amp; = 2 \begin{bmatrix} 7 &amp; -2 &amp; 11 \\ 1131 &amp; \pi &amp; -\sqrt{13} \end{bmatrix} \cdot \meye \\
    &amp; = \begin{bmatrix} 14 &amp; -4 &amp; 22 \\ 2262 &amp; 2\pi &amp; -2\sqrt{13} \end{bmatrix}.
\end{split}
\]</span></p>
</div>
</div>
</section>
<section id="inverse" class="level3" data-number="4.4.2">
<h3 data-number="4.4.2" class="anchored" data-anchor-id="inverse"><span class="header-section-number">4.4.2</span> Inverse</h3>
<p>We are now going to introduce a major simplification.</p>
<div id="def-inverse-square" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.5 (Square matrix) </strong></span>A <strong>square</strong> matrix has the same number of rows as columns.</p>
</div>
<p>Here is what we seek from a multiplicative inverse.</p>
<div id="def-" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.6 (Inverse) </strong></span>Suppose <span class="math inline">\(\bfA\)</span> is a square matrix. A matrix <span class="math inline">\(\mathbf{Z}\)</span> of the same size such that <span class="math inline">\(\mathbf{Z}\bfA = \meye\)</span> and <span class="math inline">\(\bfA\mathbf{Z}=\meye\)</span> is called the <strong>inverse</strong> of <span class="math inline">\(\bfA\)</span>, written <span class="math inline">\(\mathbf{Z} = \bfA^{-1}\)</span>. In this case we say <span class="math inline">\(\bfA\)</span> is <strong>invertible</strong>. A matrix that has no inverse is <strong>singular</strong>.</p>
</div>
<p>The definition of inverse mentions that both <span class="math inline">\(\bfA\mathbf{Z}\)</span> and <span class="math inline">\(\mathbf{Z}\bfA\)</span> are the identity matrix. It turns out that one of these facts always implies the other.</p>
<div id="thm-inverse-order" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.4 </strong></span>If <span class="math inline">\(\bfA\)</span> and <span class="math inline">\(\mathbf{Z}\)</span> are square matrices, then <span class="math inline">\(\bfA\mathbf{Z} = \meye\)</span> if and only if <span class="math inline">\(\mathbf{Z}\bfA = \meye\)</span>. In either case, <span class="math inline">\(\mathbf{Z} = \bfA^{-1}\)</span>.</p>
</div>
<p><em>Finding</em> the inverse of a given square <span class="math inline">\(\bfA\)</span> is usually hard. But <em>checking</em> whether a proposed <span class="math inline">\(\mathbf{Z}\)</span> is the inverse of <span class="math inline">\(\bfA\)</span> is easy: just multiply them together (in either order) and see if you get an identity matrix.</p>
<div id="exm-matrix-inverse" class="theorem example" data-chapter="4" data-description="Matrix inverse">
<p><span class="theorem-title"><strong>Example 4.7 </strong></span>The matrix <span class="math inline">\(\mathbf{R}(\theta) = \begin{bmatrix} \cos(\theta) &amp; -\sin(\theta) \\ \sin(\theta) &amp; \cos(\theta) \end{bmatrix}\)</span> performs rotation in the plane around the origin by angle <span class="math inline">\(\theta\)</span>. Show that <span class="math inline">\(\mathbf{R}(-\theta)\)</span> is the inverse of <span class="math inline">\(\mathbf{R}(\theta)\)</span>.</p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>All we need to do is to check that the product, in either order, is the identity matrix:</p>
<p><span class="math display">\[
\begin{split}
\mathbf{R}(-\theta)\mathbf{R}(\theta) &amp;= \begin{bmatrix}
\cos(-\theta) &amp; -\sin(-\theta) \\ \sin(-\theta) &amp; \cos(-\theta)
\end{bmatrix} \begin{bmatrix}
\cos(\theta) &amp; -\sin(\theta) \\ \sin(\theta) &amp; \cos(\theta)
\end{bmatrix} \\
&amp;= \begin{bmatrix}
\cos(\theta) &amp; \sin(\theta) \\ -\sin(\theta) &amp; \cos(\theta)
\end{bmatrix} \begin{bmatrix}
\cos(\theta) &amp; -\sin(\theta) \\ \sin(\theta) &amp; \cos(\theta)
\end{bmatrix} \\
&amp;= \begin{bmatrix}
\cos^2(\theta)+\sin^2(\theta) &amp; -\cos(\theta)\sin(\theta) + \sin(\theta)\cos(\theta) \\
  -\sin(\theta)\cos(\theta) + \cos(\theta)\sin(\theta)  &amp; \sin^2(\theta) + \cos^2(\theta)
\end{bmatrix} \\
&amp;= \twomat{1}{0}{0}{1}.
\end{split}
\]</span></p>
</div>
</div>
<p>If <span class="math inline">\(\mathbf{S}\)</span> is an <span class="math inline">\(n\times n\)</span> matrix of all zeros, then <span class="math inline">\(\mathbf{S}\bfA\)</span> and <span class="math inline">\(\bfA\mathbf{S}\)</span> are also zero matrices whenever the sizes are compatible. Therefore, <span class="math inline">\(\mathbf{S}\)</span> is singular—no inverse is possible, just like for the scalar zero. But unlike with scalars, there are other, nonzero singular matrices.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Some nonzero matrices are singular.</p>
</div>
</div>
<div id="exm-inverse-singular" class="theorem example" data-chapter="4" data-description="Singular matrix">
<p><span class="theorem-title"><strong>Example 4.8 </strong></span>Let <span class="math inline">\(\bfA = \twomat{0}{0}{1}{0}\)</span>. Suppose that</p>
<p><span class="math display">\[
\meye = \twomat{a}{b}{c}{d} \bfA = \twomat{b}{0}{d}{0}.
\]</span></p>
<p>This is clearly impossible for any choices of <span class="math inline">\(a,b,c,d\)</span>. Hence <span class="math inline">\(\bfA\)</span> is singular.</p>
</div>
</section>
<section id="properties-2" class="level3" data-number="4.4.3">
<h3 data-number="4.4.3" class="anchored" data-anchor-id="properties-2"><span class="header-section-number">4.4.3</span> Properties</h3>
<p>Here are some facts about inverses that we will use without justification.</p>
<div id="thm-inverse-properties" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.5 </strong></span>If <span class="math inline">\(\bfA\)</span> is an invertible square matrix, then:</p>
<ol type="1">
<li><span class="math inline">\(\bfA^{-1}\)</span> is unique.</li>
<li><span class="math inline">\((\bfA^{-1})^{-1} = \bfA\)</span>; that is, <span class="math inline">\(\bfA\)</span> is the inverse of <span class="math inline">\(\bfA^{-1}\)</span>.</li>
<li>If <span class="math inline">\(c\)</span> is a nonzero number, then <span class="math inline">\((c\bfA)^{-1}= \dfrac{1}{c}\bfA^{-1}\)</span>.</li>
<li>If <span class="math inline">\(\bfB\)</span> is invertible and the same size as <span class="math inline">\(\bfA\)</span>, then <span class="math inline">\(\bfA\bfB\)</span> is invertible and</li>
</ol>
<p><span id="eq-inverse-product"><span class="math display">\[
(\bfA\bfB)^{-1} = \bfB^{-1}\bfA^{-1}.
\tag{4.5}\]</span></span></p>
</div>
<p>The last identity above is easy to get wrong, so it bears restatement (and a little generalization) in words:</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>The inverse of a product of two or more invertible matrices is the product of the inverses <em>in the reverse order</em>.</p>
</div>
</div>
<p>In <a href="#sec-matrix-times-matrix" class="quarto-xref"><span>Section&nbsp;4.3</span></a> we saw some counterintuitive properties of matrix multiplication. Those were due entirely to matrix singularity. Specifically, in <a href="#exm-matrix-cancellation" class="quarto-xref">Example&nbsp;<span>4.5</span></a>, we saw that</p>
<p><span class="math display">\[
\bfA = \twomat{0}{0}{1}{0}
\]</span></p>
<p>implies that <span class="math inline">\(\bfA^2 = \bfzero\)</span>. This is possible only because, as shown in <a href="#exm-inverse-singular" class="quarto-xref">Example&nbsp;<span>4.8</span></a>, <span class="math inline">\(\bfA\)</span> is singular. According to <a href="#thm-inverse-properties" class="quarto-xref">Theorem&nbsp;<span>4.5</span></a>, the product of invertible matrices is invertible, so that product can’t be zero. We can refine our earlier observation:</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>A product that incudes a nonzero singular matrix may be zero.</p>
</div>
</div>
<p>Similarly, the “lost” cancellation property,</p>
<p><span class="math display">\[
\bfA \bfB = \bfA \mathbf{C} \implies \bfB = \mathbf{C} \qquad \text{(FALSE!)},
\]</span></p>
<p>becomes true if <span class="math inline">\(\bfA\)</span> is invertible. The proof is easy:</p>
<p><span class="math display">\[
\bfA^{-1}( \bfA \bfB) = (\bfA^{-1} \bfA) \bfB = (\meye) \bfB = \bfB,
\]</span></p>
<p>and since we can do the same to show that <span class="math inline">\(\bfA^{-1}(\bfA\mathbf{C}) = \mathbf{C}\)</span>, we conclude that <span class="math inline">\(\bfB=\mathbf{C}\)</span>.</p>
</section>
<section id="diagonal-matrix" class="level3" data-number="4.4.4">
<h3 data-number="4.4.4" class="anchored" data-anchor-id="diagonal-matrix"><span class="header-section-number">4.4.4</span> Diagonal matrix</h3>
<div id="def-diagonal-matrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.7 </strong></span>A <strong>diagonal matrix</strong> <span class="math inline">\(\mathbf{D}\)</span> is one in which <span class="math inline">\(D_{ij}=0\)</span> whenever <span class="math inline">\(i\neq j\)</span>.</p>
</div>
<p>If any diagonal element <span class="math inline">\(D_{ii}\)</span> is zero, then a diagonal matrix is singular. Otherwise, its inverse is trivial, thanks to how matrix multiplication is defined.</p>
<div id="thm-linalg-inversediag" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.6 (Inverse of a diagonal matrix) </strong></span><span id="eq-linalg-inversediag"><span class="math display">\[
\begin{bmatrix} A_{11} &amp; &amp; &amp; \\  &amp; A_{22} &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; A_{nn} \end{bmatrix}^{-1} = \begin{bmatrix} \frac{1}{A_{11}} &amp; &amp; &amp; \\  &amp; \frac{1}{A_{22}} &amp; &amp; \\ &amp; &amp; \ddots &amp; \\ &amp; &amp; &amp; \frac{1}{A_{nn}} \end{bmatrix}
\tag{4.6}\]</span></span></p>
</div>
</section>
<section id="times-2" class="level3" data-number="4.4.5">
<h3 data-number="4.4.5" class="anchored" data-anchor-id="times-2"><span class="header-section-number">4.4.5</span> <span class="math inline">\(2\times 2\)</span></h3>
<p>In the <span class="math inline">\(2\times 2\)</span> case, the inverse is easy enough to memorize.</p>
<div id="thm-linalg-inverse2by2" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.7 (Inverse of <span class="math inline">\(2\times 2\)</span>) </strong></span><span id="eq-linalg-inverse2by2"><span class="math display">\[
\begin{bmatrix} a &amp; b \\ c &amp; d \end{bmatrix}^{-1} = \frac{1}{ad-bc}\: \begin{bmatrix} d &amp; -b \\ -c &amp; a \end{bmatrix}.
\tag{4.7}\]</span></span></p>
<p>This formula breaks down if <span class="math inline">\(ad=bc\)</span>, in which case the matrix is singular.</p>
</div>
</section>
</section>
<section id="fundamental-theorem" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="fundamental-theorem"><span class="header-section-number">4.5</span> Fundamental Theorem</h2>
<p>The following theorem is in every linear algebra course, but it does not have a universally accepted name.</p>
<div id="thm-FTLA1" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.8 (Fundamental Theorem of Linear Algebra, FTLA) </strong></span>If <span class="math inline">\(\bfA\)</span> is an <span class="math inline">\(n\times n\)</span> matrix, then each of these statements is equivalent to all of the others.</p>
<ol type="1">
<li><span class="math inline">\(\bfA\)</span> is invertible.</li>
<li>The linear system <span class="math inline">\(\bfA\bfx=\bfb\)</span> has the unique solution <span class="math inline">\(\bfx=\bfA^{-1}\bfb\)</span>. <!-- 3. The null space of $\bfA$ is just $\{\bfzero\}$. --></li>
<li>The RRE form of <span class="math inline">\(\bfA\)</span> is the identity matrix.</li>
<li><span class="math inline">\(\rank(\bfA)=n\)</span>.</li>
</ol>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>Because the statements in <a href="#thm-FTLA1" class="quarto-xref">Theorem&nbsp;<span>4.8</span></a> are equivalent, so are their negations. That is, if <span class="math inline">\(\bfA\)</span> is an <span class="math inline">\(n\times n\)</span> matrix, then these statements are all equivalent as well:</p>
<ol type="1">
<li><span class="math inline">\(\bfA\)</span> is singular.</li>
<li>The linear system <span class="math inline">\(\bfA\bfx=\bfb\)</span> has infinitely many solutions or is inconsistent.</li>
<li>The RRE form of <span class="math inline">\(\bfA\)</span> has at least one row of zeros.</li>
<li><span class="math inline">\(\rank(\bfA) &lt; n\)</span>.</li>
</ol>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>The solution formula <span class="math inline">\(\bfx=\bfA^{-1}\bfb\)</span> from <a href="#thm-FTLA1" class="quarto-xref">Theorem&nbsp;<span>4.8</span></a> is theoretically valuable but can be applied only if the inverse is available. Computing a matrix inverse is usually harder than doing row elimination on a linear system, so it’s not a useful algorithm in general.</p>
</div>
</div>
</section>
<section id="sec-matrix-subspaces" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="sec-matrix-subspaces"><span class="header-section-number">4.6</span> Subspaces</h2>
<p>You are familiar with the idea that the <span class="math inline">\(x\)</span>-axis is a special subset of the plane, and that the <span class="math inline">\(xy\)</span>-plane is a special subset of <span class="math inline">\(\real^3\)</span>. These examples generalize in an important way.</p>
<div id="def-subspaces-subspace" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.8 (Subspace) </strong></span>A <strong>subspace</strong> of <span class="math inline">\(\real^n\)</span> is a subset <span class="math inline">\(S\)</span> satisfying two conditions:</p>
<ol type="1">
<li>The zero vector is in <span class="math inline">\(S\)</span>.</li>
<li>Every linear combination of vectors in <span class="math inline">\(S\)</span> is also in <span class="math inline">\(S\)</span>. (This is called <em>closure</em>.)</li>
</ol>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>We will be making statements about real spaces like <span class="math inline">\(\real^n\)</span>, but everything also works for the complex case <span class="math inline">\(\complex^n\)</span>, which turns out to be important later.</p>
</div>
</div>
<div id="exm-subspaces-plane" class="theorem example" data-chapter="4" data-description="Planes and subspaces">
<p><span class="theorem-title"><strong>Example 4.9 </strong></span>The equation <span class="math inline">\(x + 2y + 3z = 0\)</span> describes a plane passing through the origin in <span class="math inline">\(\real^3\)</span>. It’s clear geometrically that scaling a vector in the plane leaves you in the plane, and adding vectors in the plane does as well. This is enough to show that this plane is a subspace of <span class="math inline">\(\real^3\)</span>.</p>
<p><!-- In fact, it is the null space of the matrix $\begin{bmatrix} 1 & 2 & 3 \end{bmatrix}.$ --></p>
<p>The equation <span class="math inline">\(x+y+z=1\)</span> is also a plane in <span class="math inline">\(\real^3\)</span>, but it does not pass through the origin, so it cannot be a subspace.</p>
</div>
<div id="exm-subspaces-zero" class="theorem example" data-chapter="4" data-description="The trivial subspace">
<p><span class="theorem-title"><strong>Example 4.10 </strong></span>The singleton set <span class="math inline">\(\{\bfzero\}\)</span> is a subspace of <span class="math inline">\(\real^n\)</span> for any <span class="math inline">\(n\)</span>. It’s called the <em>trivial subspace</em>.</p>
</div>
<p>Here is a common way to encounter subspaces: the span of a set of vectors.</p>
<div id="thm-subspaces-span" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.9 </strong></span>If <span class="math inline">\(S=\span(\bfv_1,\ldots,\bfv_k)\)</span> for any vectors <span class="math inline">\(\bfv_j\)</span> in <span class="math inline">\(\real^n\)</span>, then <span class="math inline">\(S\)</span> is a subspace of <span class="math inline">\(\real^n\)</span>.</p>
</div>
<section id="column-space" class="level3" data-number="4.6.1">
<h3 data-number="4.6.1" class="anchored" data-anchor-id="column-space"><span class="header-section-number">4.6.1</span> Column space</h3>
<p>Each matrix generates several subspaces associated with it.</p>
<div id="def-subspaces-column" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.9 (Column space) </strong></span>Let <span class="math inline">\(\bfA\)</span> be an <span class="math inline">\(m\times n\)</span> matrix. The <strong>column space</strong> of <span class="math inline">\(\bfA\)</span>, <span class="math inline">\(\colsp(\bfA)\)</span>, is the span of the columns of <span class="math inline">\(\bfA\)</span>.</p>
</div>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Important
</div>
</div>
<div class="callout-body-container callout-body">
<p>We have encountered column spaces a lot, actually, just not by name. Here is a collection of equivalent statements:</p>
<ol type="1">
<li><span class="math inline">\(\bfb\)</span> is in the column space of <span class="math inline">\(\bfA\)</span>.</li>
<li><span class="math inline">\(\bfb\)</span> is a linear combination of the columns of <span class="math inline">\(\bfA\)</span>.</li>
<li><span class="math inline">\(\bfA\bfx=\bfb\)</span> for at least one choice of <span class="math inline">\(\bfx\)</span>.</li>
</ol>
</div>
</div>
<p>The last item above implies that the column space is the set of all vectors <span class="math inline">\(\bfA\bfx\)</span> for some choice of <span class="math inline">\(\bfx\)</span>. It’s also known as the <em>range</em> of <span class="math inline">\(\bfA\)</span> for this reason, by thinking of <span class="math inline">\(\bfA\)</span> as the function <span class="math inline">\(\mathbf{f}(\bfx)=\bfA\bfx\)</span>.</p>
<div id="exm-subspaces-column" class="theorem example" data-chapter="4" data-description="Is it in the column space?">
<p><span class="theorem-title"><strong>Example 4.11 </strong></span>Is <span class="math inline">\(\threevec{1}{2}{3}\)</span> in the column space of <span class="math inline">\(\bfA = \begin{bmatrix} 1 &amp; 1 \\ -1 &amp; 1 \\ 2 &amp; 1 \end{bmatrix}\)</span>?</p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>We can check by looking at the consistency of the system <span class="math inline">\(\bfA\bfx = \threevec{1}{2}{3}\)</span>. The augmented matrix is</p>
<p><span class="math display">\[
\augmat{\begin{matrix} 1 &amp; 1 \\ -1 &amp; 1 \\ 2 &amp; 1 \end{matrix}}{\begin{matrix} 1 \\ 2 \\ 3 \end{matrix}}
\stackrel{\text{RRE}}{\implies}
\augmat{\begin{matrix} 1 &amp; 0 \\ 0 &amp; 1 \\ 0 &amp; 0 \end{matrix}}{\begin{matrix} 0 \\ 0 \\ 1 \end{matrix}}.
\]</span></p>
<p>This system is inconsistent, so the given vector is not in the column space.</p>
</div>
</div>
<!-- 
There is a strong correspondence between a nonhomogeneous linear ODE $\opA[x]=f$ and a nonhomogeneous linear system $\bfA\bfx=\bfb$. 

::::{#thm-linsys-nonhomogeneous}
If $\bfu$ is in the nullspace of $\bfA$ and $\bfv$ is any solution of $\bfA\bfx = \bfb$, then $\bfu+\bfv$ is also a solution of $\bfA\bfx = \bfb$.
::::
:::{.proof}
$$
\bfA(\bfu + \bfv) = \bfA\bfu + \bfA\bfv = \bfzero + \bfb = \bfb. 
$$
:::

::::{#exm-nonhomogeneous-1D chapter=3 description="Nullspace in 2D"}
Suppose 

$$
\begin{bmatrix}
2 & -3
\end{bmatrix}
\bfx = \begin{bmatrix}
5
\end{bmatrix}. 
$$

Geometrically, all solutions $[x_1,\:x_2] \in \real^2$ lie on the line defined by $2x_1 - 3x_2 = 5$. Note that the vector $[1,\:-1]$ is one such solution. 

The null space of the matrix is the set of vectors such that $2x_1-3x_2=0$. If we let $x_2=t$ be a free parameter, then $x_1=\frac{3}{2}t$. So we can write solutions of the original problem in the form

$$
\bfx = \begin{bmatrix}
\tfrac{3}{2}t \\ t 
\end{bmatrix} +
\begin{bmatrix}
1 \\ -1
\end{bmatrix}
= 
\begin{bmatrix}
1 + \tfrac{3}{2}t \\ -1 + t
\end{bmatrix},
$$

which is simply one way to parameterize the line $2x_1 - 3x_2 = 5$.
::::
 -->
</section>
<section id="null-space" class="level3" data-number="4.6.2">
<h3 data-number="4.6.2" class="anchored" data-anchor-id="null-space"><span class="header-section-number">4.6.2</span> Null space</h3>
<p>Here is another subspace automatically associated with a matrix.</p>
<div id="def-nullspace-nullspace" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.10 </strong></span>The <strong>null space</strong> of a matrix <span class="math inline">\(\bfA\)</span>, written <span class="math inline">\(\nullsp(\bfA)\)</span>, is the set of all solutions to the homogeneous linear system with coefficient matrix <span class="math inline">\(\bfA\)</span>.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Sometimes the null space is called the <em>kernel</em> of the matrix.</p>
</div>
</div>
<p>By definition, <span class="math inline">\(\{\bfzero\}\)</span> is in the null space of every matrix.</p>
<p>To find the members of the null space of <span class="math inline">\(\bfA\)</span>, we solve the homogeneous system <span class="math inline">\(\bfA\bfx=\bfzero\)</span>. Because row operations can never change a column of zeros, we can use row elimination to find the RRE form of <span class="math inline">\(\bfA\)</span> and then read off the null space.</p>
<div id="exm-nullspace-span" class="theorem example" data-chapter="3" data-description="Expressing nullspace via span">
<p><span class="theorem-title"><strong>Example 4.12 </strong></span>Suppose the RRE form of a matrix <span class="math inline">\(\bfA\)</span> is</p>
<p><span class="math display">\[
\mathbf{R} =
\begin{bmatrix}
0 &amp; 1 &amp; 4 &amp; 0 &amp; 1 \\
0 &amp; 0 &amp; 0  &amp; 1 &amp; -3 \\
0 &amp; 0 &amp; 0  &amp; 0 &amp; 0  \\
0 &amp; 0 &amp; 0  &amp; 0 &amp; 0
\end{bmatrix}.
\]</span></p>
<p>Therefore, the RRE form of the augmented matrix <span class="math inline">\(\augmat{\mathbf{A}}{\boldsymbol{0}}\)</span> is <span class="math inline">\(\augmat{\mathbf{R}}{\boldsymbol{0}}\)</span>. The pivot columns are 2 and 4, which makes <span class="math inline">\(x_1=r\)</span>, <span class="math inline">\(x_3=s\)</span>, and <span class="math inline">\(x_5=t\)</span> free variables. The nonzero rows lead to</p>
<p><span class="math display">\[
\begin{split}
x_2 + 4x_3 + x_5 &amp;= 0 &amp;\quad ⇒ \quad x_2 &amp;= -4s-t,\\
x_4 -3x_5 &amp;= 0 &amp; \quad ⇒ \quad x_4 &amp;= 3t.
\end{split}
\]</span></p>
<p>One way to express a generic solution vector in the null space is by a linear combination of constant vectors:</p>
<p><span class="math display">\[
\begin{bmatrix}
  r \\ -4s-t \\ s \\ 3t\\ t
\end{bmatrix}
= r \begin{bmatrix}
  1 \\ 0 \\ 0 \\ 0 \\ 0
\end{bmatrix}
+ s \begin{bmatrix}
  0 \\ -4 \\ 0 \\ 1 \\ 0
\end{bmatrix}
+ t \begin{bmatrix}
  0 \\ -1 \\ 0 \\ 3 \\ 1
\end{bmatrix} = r\bfv_1 + s\bfv_2 + t\bfv_3 .
\]</span></p>
<p>Hence <span class="math inline">\(\nullsp(\bfA)=\span(\bfv_1,\bfv_2,\bfv_3)\)</span>, where the <span class="math inline">\(\bfv_j\)</span> are the constant vectors above.</p>
</div>
</section>
<section id="basis" class="level3" data-number="4.6.3">
<h3 data-number="4.6.3" class="anchored" data-anchor-id="basis"><span class="header-section-number">4.6.3</span> Basis</h3>
<p><img src="basis-handshake.jpg" class="img-fluid"></p>
<div id="def-subspaces-basis" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.11 (Basis) </strong></span>A <strong>basis</strong> of a subspace <span class="math inline">\(S\)</span> is any set of linearly independent vectors that spans <span class="math inline">\(S\)</span>.</p>
</div>
<p>Finding a basis for a null space was demonstrated in <a href="#exm-nullspace-span" class="quarto-xref">Example&nbsp;<span>4.12</span></a>. The column space is also found from the RRE form.</p>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.10 </strong></span>Let <span class="math inline">\(\bfA\)</span> have RRE form with pivot columns numbered <span class="math inline">\(j_1,\ldots,j_r\)</span>. Then columns <span class="math inline">\(j_1,\ldots,j_r\)</span> of <span class="math inline">\(\bfA\)</span> are a basis for <span class="math inline">\(\colsp(\bfA)\)</span>.</p>
</div>
<div id="exm-subspaces-colnull" class="theorem example" data-chapter="4" data-description="Bases for matrix subspaces">
<p><span class="theorem-title"><strong>Example 4.13 </strong></span>Find bases for the null space and column space of</p>
<p><span class="math display">\[
\bfA = \begin{bmatrix}
1 &amp; 2 &amp; 0 &amp; -4 \\
-2 &amp; -4 &amp; 1 &amp; 9 \\
-3 &amp; -6 &amp; 1 &amp; 13 \\
-2 &amp; -4 &amp; 0 &amp; 8   
\end{bmatrix}.
\]</span></p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>You can compute that the RRE form of <span class="math inline">\(\bfA\)</span> is</p>
<p><span class="math display">\[
\begin{bmatrix}
1 &amp; 2 &amp; 0 &amp; -4 \\
0 &amp; 0 &amp; 1 &amp; 1 \\
0 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 0   
\end{bmatrix}.
\]</span></p>
<p>To get a basis for <span class="math inline">\(\colsp(\bfA)\)</span> we choose columns 1 and 3 of <span class="math inline">\(\bfA\)</span>, i. e., <span class="math inline">\(\{[1,-2,-3,-2], [0,1,1,0] \}\)</span>.</p>
<p>The homogeneous system <span class="math inline">\(\bfA\bfx = \bfzero\)</span> has free variables <span class="math inline">\(x_2=s\)</span>, <span class="math inline">\(x_4=t\)</span>. Solving for the other variables gives the solution set</p>
<p><span class="math display">\[
\bfx = s \begin{bmatrix} -2 \\ 1 \\ 0 \\ 0 \end{bmatrix} + t \begin{bmatrix} 4 \\ 0 \\ -1 \\ 1 \end{bmatrix},
\]</span></p>
<p>which makes <span class="math inline">\(\{[-2,1,0,0],[4,0,-1,1] \}\)</span> a basis for <span class="math inline">\(\nullsp(\bfA)\)</span>.</p>
</div>
</div>
<div id="exm-subspaces-findbasis" class="theorem example" data-chapter="4" data-description="Basis for a span">
<p><span class="theorem-title"><strong>Example 4.14 </strong></span>Find a basis for span of the vectors <span class="math inline">\(\bfv_1=[1,-2,-3,-2]\)</span>, <span class="math inline">\(\bfv_2=[2,-4,-6,-4]\)</span>, <span class="math inline">\(\bfv_3=[0,1,1,0]\)</span>, <span class="math inline">\(\bfv_4=[-4,9,13,8]\)</span>.</p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>If we use the given vectors as columns of a matrix, then their span is equivalent to the column space of the matrix:</p>
<p><span class="math display">\[
\colsp\left(
\begin{bmatrix}
1 &amp; 2 &amp; 0 &amp; -4 \\
-2 &amp; -4 &amp; 1 &amp; 9 \\
-3 &amp; -6 &amp; 1 &amp; 13 \\
-2 &amp; -4 &amp; 0 &amp; 8   
\end{bmatrix}
\right).
\]</span></p>
<p>This is the same matrix whose column space was found in <a href="#exm-subspaces-colnull" class="quarto-xref">Example&nbsp;<span>4.13</span></a>. Columns 1 and 3 are the pivot columns, and we get the basis <span class="math inline">\(\bfv_1,\bfv_3\)</span> as before.</p>
</div>
</div>
</section>
<section id="dimension" class="level3" data-number="4.6.4">
<h3 data-number="4.6.4" class="anchored" data-anchor-id="dimension"><span class="header-section-number">4.6.4</span> Dimension</h3>
<p>You have an intuitive idea of dimension. Bases let us lock it down for all subspaces.</p>
<div id="thm-subspaces-dimension" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.11 </strong></span>Every basis for a subspace <span class="math inline">\(S\)</span> has the same number of members.</p>
</div>
<div id="def-subspaces-dimension" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.12 (Dimension) </strong></span>The <strong>dimension</strong> of a subspace <span class="math inline">\(S\)</span>, written <span class="math inline">\(\dim(S)\)</span>, is the number of vectors in any basis of <span class="math inline">\(S\)</span>. The dimension of the singleton subspace <span class="math inline">\(\{\bfzero\}\)</span> is defined to be zero.</p>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>As you would expect, <span class="math inline">\(\dim(\real^n)=n\)</span>.</p>
</div>
</div>
<p>Relative to a subspace <span class="math inline">\(S\)</span>, a set of vectors has three properties: the number of members, whether they are independent, and whether they span <span class="math inline">\(S\)</span>. The following theorem shows that knowing any two of these properties determines the third.</p>
<div id="thm-" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.12 </strong></span>Suppose <span class="math inline">\(V\)</span> is a set of <span class="math inline">\(k\)</span> vectors in subspace <span class="math inline">\(S\)</span>.</p>
<ol type="1">
<li>If <span class="math inline">\(k &lt; \dim(S)\)</span>, then <span class="math inline">\(V\)</span> cannot span <span class="math inline">\(S\)</span>.</li>
<li>If <span class="math inline">\(k &gt; \dim(S)\)</span>, then <span class="math inline">\(V\)</span> cannot be linearly independent.</li>
<li>Suppose <span class="math inline">\(k=\dim(S)\)</span>. If <span class="math inline">\(V\)</span> is independent or if <span class="math inline">\(V\)</span> spans <span class="math inline">\(S\)</span>, then <span class="math inline">\(V\)</span> is a basis for <span class="math inline">\(S\)</span>.</li>
</ol>
</div>
<div id="exm-subspaces-dimension" class="theorem example" data-chapter="4" data-description="Too few to span">
<p><span class="theorem-title"><strong>Example 4.15 </strong></span>Determine whether the vectors <span class="math inline">\(\bfv_1=[1,2,3]\)</span>, <span class="math inline">\(\bfv_2=[2,4,0]\)</span> are a basis of <span class="math inline">\(\real^3\)</span>.</p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>Since <span class="math inline">\(\real^3\)</span> is 3-dimensional, and there are only 2 vectors, it’s impossible for them to span it, so they are not a basis.</p>
</div>
</div>
<div id="exm-subspaces-dimension" class="theorem example" data-chapter="4" data-description="Too many to be independent">
<p><span class="theorem-title"><strong>Example 4.16 </strong></span>Determine whether the vectors <span class="math inline">\(\bfv_1=[1,2]\)</span>, <span class="math inline">\(\bfv_2=[3,4]\)</span>, <span class="math inline">\(\bfv_3=[1,1]\)</span> are a basis of <span class="math inline">\(\real^2\)</span>.</p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>Since <span class="math inline">\(\real^2\)</span> is 2-dimensional, and there are 3 vectors, it’s impossible for them to be independent, so they are not a basis.</p>
</div>
</div>
<div id="exm-subspaces-dimension" class="theorem example" data-chapter="4" data-description="Dimension of a subspace">
<p><span class="theorem-title"><strong>Example 4.17 </strong></span>Determine whether the vectors <span class="math inline">\(\bfv_1=[3,2,1]\)</span>, <span class="math inline">\(\bfv_2=[0,-1,2]\)</span>, <span class="math inline">\(\bfv_3=[1,1,1]\)</span> are a basis of <span class="math inline">\(\real^3\)</span>.</p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>We find a basis for their span by putting them as columns of a matrix, then looking at its column space:</p>
<p><span class="math display">\[
\begin{bmatrix}
3 &amp; 0 &amp; 1 \\ 2 &amp; -1 &amp; 1 \\ 1 &amp; 2 &amp; 1
\end{bmatrix}
\stackrel{\text{RRE}}{\implies}
\begin{bmatrix}
1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1
\end{bmatrix}.
\]</span></p>
<p>Every column is a pivot column. The original three vectors form a basis for their span, so they are independent. Since there are 3 of them, they are also a basis of the 3-dimensional <span class="math inline">\(\real^3\)</span>.</p>
</div>
</div>
<p>Earlier we defined rank as the number of pivot columns in the RRE form of the matrix. So now we have:</p>
<div id="thm-subspaces-rank" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.13 </strong></span>For any <span class="math inline">\(m\times n\)</span> matrix <span class="math inline">\(\bfA\)</span>, <span class="math inline">\(\rank(\bfA)=\dim(\colsp(\bfA))\)</span>.</p>
</div>
<p>The dimension of the null space also gets its own name.</p>
<div id="def-subspaces-nullity" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.13 (Nullity) </strong></span>The <strong>nullity</strong> of a matrix <span class="math inline">\(\bfA\)</span>, written <span class="math inline">\(\nullity(\bfA)\)</span>, is the dimension of <span class="math inline">\(\nullsp(\bfA)\)</span>.</p>
</div>
<p>Finally, we have a fancy way of saying that every variable in a linear system is either a pivot variable or a free variable:</p>
<div id="thm-subspaces-nullity" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.14 </strong></span>For any <span class="math inline">\(m\times n\)</span> matrix <span class="math inline">\(\bfA\)</span>,</p>
<ol type="1">
<li><span class="math inline">\(\dim(\nullsp(\bfA))\)</span> is the number of free variables in the RRE form of <span class="math inline">\(\mathbf{A}\)</span>.</li>
<li><span class="math inline">\(\rank(\bfA) + \nullity(\bfA) = n\)</span>.</li>
</ol>
</div>
<p>Here is a table that tries to organize much of the language of the linear algebra learned so far.</p>
<div id="tbl-linalg-related" class="anchored">
<table class="table">
<caption>Table&nbsp;4.1: Related statements in different areas of linear algebra</caption>
<colgroup>
<col style="width: 44%">
<col style="width: 24%">
<col style="width: 31%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Linear combinations</th>
<th style="text-align: center;">Matrices</th>
<th style="text-align: center;">Linear systems</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><span class="math inline">\(\bfb\)</span> is a combination of columns</td>
<td style="text-align: center;"><span class="math inline">\(\bfb\in \colsp(\bfA)\)</span>; <span class="math inline">\(\bfA \bfx = \bfb\)</span></td>
<td style="text-align: center;">Solve <span class="math inline">\(\augmat{\bfA}{\bfb}\)</span></td>
</tr>
<tr class="even">
<td style="text-align: center;">columns are dependent</td>
<td style="text-align: center;">nontrivial <span class="math inline">\(\nullsp(\bfA)\)</span>; <span class="math inline">\(\nullity(\bfA) &gt; 0\)</span></td>
<td style="text-align: center;">nonzero solution of <span class="math inline">\(\augmat{\bfA}{\bfzero}\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: center;">columns are independent</td>
<td style="text-align: center;"><span class="math inline">\(\rank(A) = \text{column size of }\bfA\)</span></td>
<td style="text-align: center;">no free variables</td>
</tr>
<tr class="even">
<td style="text-align: center;">columns are a basis</td>
<td style="text-align: center;"><span class="math inline">\(\bfA\)</span> is square; <span class="math inline">\(\bfA^{-1}\)</span> exists</td>
<td style="text-align: center;">unique solution; <span class="math inline">\(\bfA\)</span> reduces to <span class="math inline">\(\meye\)</span></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
<section id="other-vector-spaces" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="other-vector-spaces"><span class="header-section-number">4.7</span> Other vector spaces</h2>
<p>Here’s where things get a little weird.</p>
<section id="matrices" class="level3" data-number="4.7.1">
<h3 data-number="4.7.1" class="anchored" data-anchor-id="matrices"><span class="header-section-number">4.7.1</span> Matrices</h3>
<p>If we stack the columns of an <span class="math inline">\(m\times n\)</span> matrix on top of one another, then we get a vector in <span class="math inline">\(\complex^{mn}\)</span>. Conversely, if we start with a vector in <span class="math inline">\(\complex^{mn}\)</span>, we can easily reshape it to be <span class="math inline">\(m\times n\)</span>. Let’s define and name these operations.</p>
<div id="def-vec-unvec" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.14 </strong></span>For fixed values of <span class="math inline">\(m\)</span> and <span class="math inline">\(n\)</span>, we define the following functions:</p>
<p><span class="math display">\[
\vec\left( \begin{bmatrix} \bfa_1 &amp; \bfa_2 &amp; \cdots &amp; \bfa_n \end{bmatrix}  \right) = \begin{bmatrix} \bfa_1 \\ \bfa_2 \\ \vdots \\ \bfa_n \end{bmatrix},
\]</span></p>
<p>which maps <span class="math inline">\(\bfA \in \cmn{m}{n}\)</span> to a vector in <span class="math inline">\(\complex^{mn}\)</span>, and its inverse function,</p>
<p><span class="math display">\[
\unvec\left( \begin{bmatrix} A_{11} \\ \vdots \\ A_{m1} \\ A_{12}\\  \vdots \\ A_{m2} \\ \vdots \\ A_{mn} \end{bmatrix} \right) = \begin{bmatrix} A_{11} &amp; \cdots &amp; A_{1n} \\ \vdots &amp; &amp; \vdots \\ A_{m1} &amp; \cdots &amp; A_{mn} \end{bmatrix}.
\]</span></p>
</div>
<p>Not only do we have a correspondence between <span class="math inline">\(\cmn{m}{n}\)</span> and <span class="math inline">\(\complex^{mn}\)</span>, the operations of addition and scalar multiplication mirror one another. For instance, if <span class="math inline">\(\bfv=\vec(\bfA)\)</span> and <span class="math inline">\(\bfw=\vec(\bfB)\)</span>, then <span class="math inline">\(\bfv+\bfw=\vec(\bfA+\bfB)\)</span>, and <span class="math inline">\(\bfA+\bfB = \unvec(\bfv) + \unvec(\bfw)\)</span>. That is, to add matrices in <span class="math inline">\(\cmn{m}{n}\)</span>, we can transform them over to <span class="math inline">\(\complex^{mn}\)</span>, add them there, and then transform the result back. The same is true for scalar multiplication. Finally, note that the vec of a zero matrix is equal to the zero vector in <span class="math inline">\(\complex^{mn}\)</span>.</p>
<p>All this is to say that the set <span class="math inline">\(\cmn{m}{n}\)</span> acts just like the set <span class="math inline">\(\complex^{mn}\)</span> when it comes to linear combinations. We can say more simply that <span class="math inline">\(\cmn{m}{n}\)</span> is a <strong>vector space</strong>.</p>
<div id="exm-space-matrices" class="theorem example" data-chapter="4" data-description="Matrices as vectors">
<p><span class="theorem-title"><strong>Example 4.18 </strong></span>Determine whether the matrix <span class="math inline">\(\twomat{1}{-4}{2}{1}\)</span> lies in the span of <span class="math inline">\(\twomat{1}{0}{0}{1}\)</span>, <span class="math inline">\(\twomat{0}{1}{1}{0}\)</span>, and <span class="math inline">\(\twomat{1}{1}{-1}{1}\)</span>.</p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>Simply reinterpret the question by mapping each given matrix to its <span class="math inline">\(\vec()\)</span> equivalent. We therefore want to know about the consistency of the linear system</p>
<p><span class="math display">\[
\augmat{\begin{matrix} 1 &amp; 0 &amp; 1 \\ 0 &amp; 1 &amp; -1 \\ 0 &amp; 1 &amp; 1 \\ 1 &amp; 0 &amp; 1 \end{matrix}}{\begin{matrix} 1 \\ 2 \\ -4 \\ 1 \end{matrix}}.
\]</span></p>
<p>The RRE form is</p>
<p><span class="math display">\[
\augmat{\begin{matrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \\ 0 &amp; 0 &amp; 0 \end{matrix}}{\begin{matrix} 4 \\ -1 \\ -3 \\ 0 \end{matrix}},
\]</span></p>
<p>which is consistent. Hence <span class="math inline">\(\twomat{1}{-4}{2}{1}\)</span> is in the span of the three given matrices.</p>
</div>
</div>
</section>
<section id="polynomials" class="level3" data-number="4.7.2">
<h3 data-number="4.7.2" class="anchored" data-anchor-id="polynomials"><span class="header-section-number">4.7.2</span> Polynomials</h3>
<div id="def-spaces-polynomials" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.15 </strong></span>Let <span class="math inline">\(\mathcal{P}_n\)</span> denote the set of all polynomials of degree <span class="math inline">\(n\)</span> or less having real coefficients.</p>
</div>
<p>For instance, <span class="math inline">\(2t^2-1\)</span> is a member of <span class="math inline">\(\mathcal{P}_2\)</span> (as well as <span class="math inline">\(\mathcal{P}_3\)</span>, <span class="math inline">\(\mathcal{P}_4\)</span>, etc.), but <span class="math inline">\(t^4+t\)</span> is not.</p>
<p>It is easy to set up a correspondence between every member of <span class="math inline">\(\mathcal{P}_n\)</span> and a vector in <span class="math inline">\(\real^{n+1}\)</span>:</p>
<p><span id="eq-polynomial-vector"><span class="math display">\[
c_0 + c_1 t + c_2 t^2 + \cdots + c_n t^n \Longleftrightarrow \begin{bmatrix} c_0 \\ c_1 \\ c_2 \\ \vdots \\ c_n \end{bmatrix}.
\tag{4.8}\]</span></span></p>
<p>As with <span class="math inline">\(\cmn^{m}{n}\)</span>, this correspondence preserves the structure of addition, scalar multiplication, and zero. Therefore, <span class="math inline">\(\mathcal{P}_n\)</span> is a vector space.</p>
<div id="exm-space-polynomials" class="theorem example" data-chapter="4" data-description="Polynomials as vectors">
<p><span class="theorem-title"><strong>Example 4.19 </strong></span>Determine whether the polynomials <span class="math inline">\(3t+4\)</span>, <span class="math inline">\(t^2-1\)</span>, and <span class="math inline">\(t^2+t\)</span> are linearly dependent.</p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>This question is identical to asking about the independence of</p>
<p><span class="math display">\[
\begin{bmatrix} 4 \\ 3 \\ 0 \end{bmatrix}, \quad \begin{bmatrix} -1 \\ 0 \\ 1 \end{bmatrix}, \quad \begin{bmatrix} 0 \\ 1 \\ 1 \end{bmatrix}.
\]</span></p>
<p>Hence we seek nontrivial solutions of the linear system</p>
<p><span class="math display">\[
\augmat{\begin{matrix} 4 &amp; -1 &amp; 0 \\ 3 &amp; 0 &amp; 1 \\ 0 &amp; 1 &amp; 1 \end{matrix}}{\begin{matrix} 0 \\ 0 \\ 0 \end{matrix}}.
\]</span></p>
<p>The RRE form is</p>
<p><span class="math display">\[
\stackrel{RRE}{\implies} \augmat{\begin{matrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1 \end{matrix}}{\begin{matrix} 0 \\ 0 \\ 0 \end{matrix}},
\]</span></p>
<p>which has a unique solution. Hence the polynomials are linearly independent.</p>
</div>
</div>
<p>The standard vectors <span class="math inline">\(\bfe_1. \ldots, \bfe_{n+1}\)</span> of <span class="math inline">\(\real^{n+1}\)</span> correspond to <span class="math inline">\(1, t, t^2, \ldots, t^n\)</span> in <span class="math inline">\(\mathcal{P}_n\)</span>.</p>
</section>
<section id="ode-solutions" class="level3" data-number="4.7.3">
<h3 data-number="4.7.3" class="anchored" data-anchor-id="ode-solutions"><span class="header-section-number">4.7.3</span> ODE solutions</h3>
<p>All solutions of the homogeneous linear ODE <span class="math inline">\(x''+x = 0\)</span> are in the form</p>
<p><span class="math display">\[
x(t) = c_1 \cos t + c_2 \sin t.
\]</span></p>
<p>We can describe <span class="math inline">\(x\)</span> as belonging to a <em>solution space</em> of the ODE that is spanned by <span class="math inline">\(\cos(t)\)</span> and <span class="math inline">\(\sin(t)\)</span>. This space supports linear combinations of its members, just like the other vector spaces. We could set up a correspondence with <span class="math inline">\(\real^2\)</span>, but that’s not as useful as the ones we’ve seen so far. For instance, <span class="math inline">\(\cos(x+\pi)\)</span> is equal to <span class="math inline">\(-\cos(x)\)</span>, which is not an easy connection to make outside the context of trigonometric functions.</p>
</section>
</section>
<section id="coordinates" class="level2" data-number="4.8">
<h2 data-number="4.8" class="anchored" data-anchor-id="coordinates"><span class="header-section-number">4.8</span> Coordinates</h2>
<p>When we want to specify a vector in, say, <span class="math inline">\(\real^3\)</span>, we usually give its three elements. But there are infinitely many different ways to express a given vector.</p>
<div id="exm-standard-coords" class="theorem example" data-chapter="4" data-description="Coordinates">
<p><span class="theorem-title"><strong>Example 4.20 </strong></span>If we specify <span class="math inline">\(\bfv = \threevec{2}{-1}{3}\)</span>, we are really making a statement about a linear combination of standard vectors in <span class="math inline">\(\real^3\)</span>:</p>
<p><span class="math display">\[
\bfv = 2\threevec{1}{0}{0} - \threevec{0}{1}{0} + 3\threevec{0}{0}{1} = 2\bfe_1 - \bfe_2 + 3\bfe_3.
\]</span></p>
<p>We can get a different expression for <span class="math inline">\(\bfv\)</span> if we use the basis <span class="math inline">\(\bfu_1 = \threevec{1}{1}{0}\)</span>, <span class="math inline">\(\bfu_2 = \threevec{0}{1}{1}\)</span>, <span class="math inline">\(\bfu_3 = \threevec{1}{0}{1}\)</span>, by solving for the coefficients in</p>
<p><span class="math display">\[
\bfv = x_1 \bfu_1 + x_2 \bfu_2 + x_3 \bfu_3.
\]</span></p>
<p>This equation is a linear system <span class="math inline">\(\mathbf{U} \bfx = \bfv\)</span>, specifically,</p>
<p><span class="math display">\[
\begin{bmatrix} 1 &amp; 0 &amp; 1 \\ 1 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 1 \end{bmatrix} \bfx = \threevec{2}{-1}{3}.
\]</span></p>
<p>Given that <span class="math inline">\(\bfu_1, \bfu_2, \bfu_3\)</span> form a basis of <span class="math inline">\(\real^3\)</span>, we know that <span class="math inline">\(\rank(\mathbf{U})=3\)</span>; therefore, the FTLA guarantees that a unique solution <span class="math inline">\(\bfx\)</span> exists.</p>
</div>
<div id="def-coordinates" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.16 (Coordinates) </strong></span>In an <span class="math inline">\(n\)</span>-dimensional vector space, the <strong>coordinates</strong> of a vector <span class="math inline">\(\bfv\)</span> relative to a basis <span class="math inline">\(\bfu_1, \ldots, \bfu_n\)</span> are the unique coefficients in the expression</p>
<p><span id="eq-coordinates"><span class="math display">\[
\bfv = x_1 \bfu_1 + \cdots + x_n \bfu_n.
\tag{4.9}\]</span></span></p>
<p>If we name the basis as <span class="math inline">\(B\)</span>, then we write the coordinates relative to <span class="math inline">\(B\)</span> as</p>
<p><span class="math display">\[
\bigl[ \bfv \bigr]_B = \begin{bmatrix} x_1 \\ x_2 \\ \cdots \\ x_n \end{bmatrix}.
\]</span></p>
<p>The <strong>standard coordinates</strong> of a vector are its coordinates relative to the standard basis. We use <span class="math inline">\(E\)</span> to denote the standard basis, with the vector space it refers to implied by context.</p>
</div>
<section id="computing-coordinates" class="level3" data-number="4.8.1">
<h3 data-number="4.8.1" class="anchored" data-anchor-id="computing-coordinates"><span class="header-section-number">4.8.1</span> Computing coordinates</h3>
<p>Here is a typical example.</p>
<div id="exm-coords-2by2" class="theorem example" data-chapter="4" data-description="Coordinates relative to a basis">
<p><span class="theorem-title"><strong>Example 4.21 </strong></span>Find the coordinates of <span class="math inline">\(\bfv = \twomat{2}{-1}{-1}{3}\)</span> relative to the basis</p>
<p><span class="math display">\[
B = \twomat{1}{1}{0}{1},\; \twomat{1}{0}{1}{1}, \; \twomat{0}{1}{0}{0}, \; \twomat{1}{1}{1}{0}.
\]</span></p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>If we write out <a href="#eq-coordinates" class="quarto-xref">Equation&nbsp;<span>4.9</span></a>, we get 4 linear equations for <span class="math inline">\(x_1,\ldots,x_4\)</span>:</p>
<p><span class="math display">\[
\begin{bmatrix} 1 &amp; 1 &amp; 0 &amp; 1 \\ 0 &amp; 1 &amp; 0 &amp; 1 \\ 1 &amp; 0 &amp; 1 &amp; 1 \\ 1 &amp; 1 &amp; 0 &amp; 0 \end{bmatrix} \bfx =
\begin{bmatrix} 2 \\ -1 \\ -1 \\ 3 \end{bmatrix}.
\]</span></p>
<p>(Note that each column of the coordinate matrix is the vec() of a basis member.) The solution of the system gives the coordinate vector:</p>
<p><span class="math display">\[
\bigl[ \bfv \bigr]_B = \bfx = \begin{bmatrix} 3 \\ 0 \\ -3 \\ -1 \end{bmatrix}.
\]</span></p>
</div>
</div>
<p>There’s some subtle sleight-of-hand here. Theoretically, a vector exists independently of any of the infinitely many ways we might choose to express it. But in practice, we often have to pick a coordinate system in order to work with that vector. Usually, that’s the standard basis, and we don’t even think of a vector as being different from its standard coordinates. Even though it isn’t stated, the problem statement in <a href="#exm-coords-2by2" class="quarto-xref">Example&nbsp;<span>4.21</span></a> is actually giving not <span class="math inline">\(\bfv\)</span> but <span class="math inline">\(\bigl[ \bfv \bigr]_E\)</span>, and the same is true for the basis members.</p>
<p>I’m going to introduce some nonstandard notation here that I think helps with these sorts of problems—and what is to come.</p>
<div id="def-coord-matrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.17 (Standard matrix) </strong></span>The <strong>standard matrix</strong> of a basis <span class="math inline">\(B\)</span> is the matrix whose columns are the basis vectors as expressed in standard coordinates. We denote it as <span class="math inline">\(\bigl[ B \bigr]_E\)</span>.</p>
</div>
<p>To be fully pedantic, if <span class="math inline">\(B=\bfu_1,\ldots,\bfu_n\)</span> is a basis of an <span class="math inline">\(n\)</span>-dimensional vector space, then</p>
<p><span class="math display">\[
\bigl[ B \bigr]_E = \begin{bmatrix} \bigl[ \bfu_1 \bigr]_E &amp; \cdots &amp; \bigl[ \bfu_n \bigr]_E \end{bmatrix}.
\]</span></p>
<p>This notation allows us to write the linear system in <a href="#exm-coords-2by2" class="quarto-xref">Example&nbsp;<span>4.21</span></a>, for instance, in an abstract form.</p>
<div id="thm-coords-abstract" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.15 </strong></span>If <span class="math inline">\(B\)</span> is a basis of a vector space and <span class="math inline">\(\bfv\)</span> is a vector in that space, then</p>
<p><span id="eq-coords-abstract"><span class="math display">\[
\bigl[ B \bigr]_E \cdot \bigl[\bfv\bigr]_B = \bigl[ \bfv \bigr]_E.
\tag{4.10}\]</span></span></p>
</div>
<p>Note the cancellation pattern in the above:</p>
<p><span class="math display">\[
\bigl[ \cancel{B} \bigr]_E \cdot \bigl[\bfv\bigr]_{\cancel{B}} = \bigl[ \bfv \bigr]_E.
\]</span></p>
</section>
</section>
<section id="change-of-basis" class="level2" data-number="4.9">
<h2 data-number="4.9" class="anchored" data-anchor-id="change-of-basis"><span class="header-section-number">4.9</span> Change of basis</h2>
<p>As stated earlier, in order to work with a vector space, we usually have to refer to a coordinate system, and the standard basis provides the default. Sometimes, though, we’d like to work with alternative bases.</p>
<p>Suppose <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> are bases for the same space. We can apply <a href="#eq-coords-abstract" class="quarto-xref">Equation&nbsp;<span>4.10</span></a> twice to get</p>
<p><span class="math display">\[
\bigl[ B \bigr]_E \cdot \bigl[\bfv\bigr]_B = \bigl[ \bfv \bigr]_E
\]</span></p>
<p>and</p>
<p><span class="math display">\[
\bigl[ C \bigr]_E \cdot \bigl[\bfv\bigr]_C = \bigl[ \bfv \bigr]_E \quad.
\]</span></p>
<p>This implies</p>
<p><span id="eq-change-of-basis-standard"><span class="math display">\[
\bigl[ B \bigr]_E \cdot \bigl[\bfv\bigr]_B = \bigl[ C \bigr]_E \cdot \bigl[\bfv\bigr]_C \quad.
\tag{4.11}\]</span></span></p>
<p>The standard matrices are invertible (hello, basis!), and we could write</p>
<p><span class="math display">\[
\bigl[\bfv\bigr]_B = \Bigl( \bigl[ B \bigr]_E^{-1} \cdot \bigl[ C \bigr]_E \Bigr) \bigl[\bfv\bigr]_C \quad.
\]</span></p>
<p>This equation allows us to change from <span class="math inline">\(C\)</span>-coordinates to <span class="math inline">\(B\)</span>-coordinates with a single matrix-vector multiplication. Such a matrix represents a <strong>change of basis</strong>.</p>
<p>Here are the key results.</p>
<div id="def-coordinate-matrix" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 4.18 </strong></span>The <strong>coordinate matrix</strong> of a basis <span class="math inline">\(C\)</span> relative to a basis <span class="math inline">\(B\)</span> of the same vector space is the matrix <span class="math inline">\(\bigl[ C \bigr]_B\)</span> whose columns are the basis vectors of <span class="math inline">\(C\)</span> expressed in <span class="math inline">\(B\)</span>-coordinates. That is, if <span class="math inline">\(C\)</span> is <span class="math inline">\(\bfu_1,\ldots,\bfu_n\)</span>, then</p>
<p><span class="math display">\[
\bigl[ C \bigr]_B = \begin{bmatrix} \bigl[ \bfu_1 \bigr]_B &amp; \cdots &amp; \bigl[ \bfu_n \bigr]_B \end{bmatrix}.
\]</span></p>
</div>
<div id="thm-change-of-basis" class="theorem">
<p><span class="theorem-title"><strong>Theorem 4.16 (Change of basis) </strong></span>Suppose that <span class="math inline">\(B\)</span> and <span class="math inline">\(C\)</span> are bases of the same vector space. Then</p>
<p><span id="eq-change-of-basis-matrix"><span class="math display">\[
\bigl[ C \bigr]_B = \bigl[ B \bigr]_E^{-1} \cdot \bigl[ C \bigr]_E\quad ,
\tag{4.12}\]</span></span></p>
<p>where <span class="math inline">\(E\)</span> is the standard basis of the space, and</p>
<p><span id="eq-change-of-basis"><span class="math display">\[
\bigl[\bfv\bigr]_B = \bigl[ C \bigr]_B \cdot \bigl[\bfv\bigr]_C \quad.
\tag{4.13}\]</span></span></p>
</div>
<p>Both <a href="#eq-change-of-basis" class="quarto-xref">Equation&nbsp;<span>4.13</span></a> and <a href="#eq-change-of-basis-matrix" class="quarto-xref">Equation&nbsp;<span>4.12</span></a> have the same cancellation pattern as <a href="#eq-coords-abstract" class="quarto-xref">Equation&nbsp;<span>4.10</span></a>, if we allow for the inverse of a matrix to swap the roles of upper/lower position. This is clearer if we rewrite <a href="#eq-change-of-basis-matrix" class="quarto-xref">Equation&nbsp;<span>4.12</span></a> as</p>
<p><span class="math display">\[
\bigl[ \cancel{B} \bigr]_{E} \cdot \bigl[ C \bigr]_{\cancel{B}} = \bigl[ C \bigr]_E\quad .
\]</span></p>
<div id="exm-change-of-basis-matrix" class="theorem example" data-chapter="4" data-description="Change of basis matrix">
<p><span class="theorem-title"><strong>Example 4.22 </strong></span>Find the matrix that changes coordinates from the <span class="math inline">\(\mathcal{P}_1\)</span> basis <span class="math inline">\(B = 1+t\)</span>, <span class="math inline">\(1-t\)</span> to the basis <span class="math inline">\(C=1\)</span>, <span class="math inline">\(1+2t\)</span>.</p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>The first step is to translate everything into <span class="math inline">\(\real^2\)</span>:</p>
<p><span class="math display">\[
\begin{split}
B &amp;= \twovec{1}{1}, \; \twovec{1}{-1} \\
C &amp;= \twovec{1}{0}, \; \twovec{1}{2}.
\end{split}
\]</span></p>
<p>The standard matrices are therefore</p>
<p><span class="math display">\[
\bigl[ B \bigr]_E = \begin{bmatrix} 1 &amp; 1  \\ 1 &amp; -1 \end{bmatrix}, \quad \bigl[ C \bigr]_E= \begin{bmatrix} 1 &amp; 1  \\ 0 &amp; 2 \end{bmatrix}.
\]</span></p>
<p>The change of basis matrix is</p>
<p><span class="math display">\[
\begin{split}
\bigl[ B \bigr]_C &amp;= \begin{bmatrix} 1 &amp; 1  \\ 0 &amp; 2 \end{bmatrix}^{-1} \begin{bmatrix} 1 &amp; 1  \\ 1 &amp; -1 \end{bmatrix} \\[1em]
&amp;= \frac{1}{2} \begin{bmatrix} 2 &amp; -1  \\ 0 &amp; 1 \end{bmatrix} \begin{bmatrix} 1 &amp; 1  \\ 1 &amp; -1 \end{bmatrix} \\[1em]
&amp;= \frac{1}{2} \begin{bmatrix} 1 &amp; 1  \\ 1 &amp; -1 \end{bmatrix}.
\end{split}
\]</span></p>
</div>
</div>
<div id="exm-change-of-basis" class="theorem example" data-chapter="4" data-description="Change of basis">
<p><span class="theorem-title"><strong>Example 4.23 </strong></span>Given the bases <span class="math inline">\(B = \threevec{1}{1}{1}\)</span>, <span class="math inline">\(\threevec{1}{0}{1}\)</span>, <span class="math inline">\(\threevec{1}{1}{0}\)</span> and <span class="math inline">\(C = \threevec{1}{0}{-1}\)</span>, <span class="math inline">\(\threevec{0}{1}{1}\)</span>, <span class="math inline">\(\threevec{0}{2}{1}\)</span> of <span class="math inline">\(\real^3\)</span>, and a vector whose <span class="math inline">\(C\)</span>-coordinates are <span class="math inline">\(\threevec{1}{2}{3}\)</span>, find its <span class="math inline">\(B\)</span>-coordinates.</p>
<div class="solution proof">
<p><span class="proof-title"><em>Solution</em>. </span>The <em>hard</em> way to solve this problem would be to first apply <a href="#thm-change-of-basis" class="quarto-xref">Theorem&nbsp;<span>4.16</span></a> to find the change-of-basis matrix <span class="math inline">\(\bigl[ B \bigr]_C\)</span>. That would require finding the inverse of a <span class="math inline">\(3\times 3\)</span> matrix.</p>
<p>The <em>easy</em> way is to use the standard basis as an intermediary, like in <a href="#eq-change-of-basis-standard" class="quarto-xref">Equation&nbsp;<span>4.11</span></a>:</p>
<p><span class="math display">\[
\begin{split}
\bigl[ B \bigr]_E \cdot \bigl[\bfv\bigr]_B &amp;= \bigl[ C \bigr]_E \cdot \bigl[\bfv\bigr]_C \\[1em]
\begin{bmatrix} 1 &amp; 1 &amp; 1 \\ 1 &amp; 0 &amp; 1 \\ 1 &amp; 1 &amp; 0 \end{bmatrix} \cdot \bigl[\bfv\bigr]_B &amp;= \begin{bmatrix} 1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 2 \\ -1 &amp; 1 &amp; 1 \end{bmatrix} \cdot \threevec{1}{2}{3} \\[1em]
\begin{bmatrix} 1 &amp; 1 &amp; 1 \\ 1 &amp; 0 &amp; 1 \\ 1 &amp; 1 &amp; 0 \end{bmatrix} \cdot \bigl[\bfv\bigr]_B &amp;= \threevec{1}{8}{4}
\end{split}
\]</span></p>
<p>This has the solution <span class="math inline">\(\bigl[\bfv\bigr]_B = \threevec{11}{-7}{-3}\)</span>.</p>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        for (let i = 0; i < 2; i++) {
          container.appendChild(note.children[i].cloneNode(true));
        }
        return container.innerHTML
      } else {
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        console.log("RESIZE");
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./linear_algebra_systems.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Linear algebraic systems</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./eigen.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Eigenvalues</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Math 351 @ UD
  </li>  
</ul>
    </div>   
    <div class="nav-footer-center">
      &nbsp;
    </div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item">
 Toby Driscoll
  </li>  
</ul>
    </div>
  </div>
</footer>




</body></html>